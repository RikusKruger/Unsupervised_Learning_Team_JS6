{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# EDSA Movie Recommendation Challenge\n",
    "Team JS6 EDSA - Climate Change Belief Analysis 2021\n",
    "\n",
    "###### Members\n",
    "1. Rikus\n",
    "2. Thobekani\n",
    "3. Carol\n",
    "4. Hlayisani"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We will be using Comet as a form of version control throughout the development of our model\r\n",
    "from comet_ml import Experiment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create an experiment with your api key\r\n",
    "experiment = Experiment(\r\n",
    "    api_key=\"KQ1UTh7hBvPLWlz3034oIgusG\",\r\n",
    "    project_name=\"edsa-movie-recommendation-challenge\",\r\n",
    "    workspace=\"thobekanimasondo84-gmail-com\",)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Introduction\n",
    "\n",
    "In todayâ€™s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n",
    "\n",
    "With this context, we as EDSA students have constructucted a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
    "\n",
    "Providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity.\n",
    "\n",
    "The evaluation metric for this model is Root Mean Square Error. Root Mean Square Error (RMSE) is commonly used in regression analysis and forecasting, and measures the standard deviation of the residuals arising between predicted and actual observed values for a modelling process. For our task of generating user movie ratings via recommendation algorithms.\n",
    "<div align=\"center\" style=\"width: 500px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://manofmany.com/wp-content/uploads/2020/04/Veboli-new-2.jpg\"\n",
    "     alt=\"Dummy image 1\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=500px/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem statement\n",
    "\n",
    "To construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1}{|\\hat{R}|} \\sum_{\\hat{r}_{ui}\\in \\hat{R}}{(r_{ui}-\\hat{r}_{ui})^2}}$$\n",
    "\n",
    "Where $$\\hat{R}$$ is the total number of recommendations generated for users and movies, with rui and $$\\hat{rui}$$ being the true and predicted ratings for user u watching movie i respectively."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Python Libraries\n",
    "Load the libraries we are going to use throughout our notebook. After which we will load our data collected from Kaggle.\n",
    "\n",
    "***This notebook was designed with the following libraries. Should you not have them already installed, simply run !pip install and obtain the desired library.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import scipy as sp\r\n",
    "\r\n",
    "# Packages for visualization\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "import surprise\r\n",
    "from surprise import Reader\r\n",
    "from surprise import Dataset\r\n",
    "from surprise.model_selection import train_test_split\r\n",
    "import time\r\n",
    "from surprise import SVD\r\n",
    "from surprise import accuracy\r\n",
    "import re\r\n",
    "import plotly.express as px\r\n",
    "import scipy as sp\r\n",
    "from wordcloud import WordCloud, STOPWORDS\r\n",
    "from surprise import Reader\r\n",
    "from surprise import Dataset\r\n",
    "from surprise.model_selection import cross_validate\r\n",
    "from surprise import NormalPredictor\r\n",
    "from surprise import KNNBasic\r\n",
    "from surprise import KNNWithMeans\r\n",
    "from surprise import KNNWithZScore\r\n",
    "from surprise import KNNBaseline\r\n",
    "from surprise import BaselineOnly\r\n",
    "from surprise import SVDpp\r\n",
    "from surprise import NMF\r\n",
    "from surprise import SlopeOne\r\n",
    "from surprise import CoClustering\r\n",
    "from surprise.accuracy import rmse\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.metrics.pairwise import cosine_similarity\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.pipeline  import Pipeline\r\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, Normalizer\r\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\r\n",
    "from catboost import CatBoostRegressor\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "\r\n",
    "# Packages for model evaluation\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.metrics import mean_absolute_error\r\n",
    "from time import time\r\n",
    "\r\n",
    "# Package to suppress warnings\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "# Packages for saving models\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Description\r\n",
    "This dataset consists of several million 5-star ratings obtained from users of the online MovieLens movie recommendation service. The MovieLens dataset has long been used by industry and academic researchers to improve the performance of explicitly-based recommender systems.\r\n",
    "\r\n",
    "**Source:**\r\n",
    "\r\n",
    "The data for the MovieLens dataset is maintained by the GroupLens research group in the Department of Computer Science and Engineering at the University of Minnesota. Additional movie content data was legally scraped from IMDB.\r\n",
    "\r\n",
    "**Supplied Files:**\r\n",
    "* genome_scores.csv - a score mapping the strength between movies and tag-related properties. Read more here\r\n",
    "* genome_tags.csv - user assigned tags for genome-related scores\r\n",
    "* imdb_data.csv - Additional movie metadata scraped from IMDB using the links.csv file.\r\n",
    "* links.csv - File providing a mapping between a MovieLens ID and associated IMDB and TMDB IDs.\r\n",
    "* sample_submission.csv - Sample of the submission format for the hackathon.\r\n",
    "* tags.csv - User assigned for the movies within the dataset.\r\n",
    "* test.csv - The test split of the dataset. Contains user and movie IDs with no rating data.\r\n",
    "* train.csv - The training split of the dataset. Contains user and movie IDs with associated rating data.\r\n",
    "\r\n",
    "**Additional Information:**\r\n",
    "\r\n",
    "The below information is provided directly from the MovieLens dataset description files:\r\n",
    "\r\n",
    "* All ratings are contained in the file train.csv. Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\r\n",
    "userId,movieId,rating,timestamp\r\n",
    "The lines within this file are ordered first by userId, then, within user, by movieId.\r\n",
    "\r\n",
    "* Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\r\n",
    "\r\n",
    "* Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\r\n",
    "\r\n",
    "* All tags are contained in the file tags.csv. Each line of this file after the header row represents one tag applied to one movie by one user, and has the following format:\r\n",
    "userId,movieId,tag,timestamp\r\n",
    "The lines within this file are ordered first by userId, then, within user, by movieId.\r\n",
    "Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.\r\n",
    "\r\n",
    "* Movie information is contained in the file movies.csv. Each line of this file after the header row represents one movie, and has the following format:\r\n",
    "movieId,title,genres\r\n",
    "Movie titles are entered manually or imported from https://www.themoviedb.org/, and include the year of release in parentheses. Errors and inconsistencies may exist in these titles.\r\n",
    "\r\n",
    "* Genres are a pipe-separated list, and are selected from the following:\r\n",
    "Action\r\n",
    "Adventure\r\n",
    "Animation\r\n",
    "Children's\r\n",
    "Comedy\r\n",
    "Crime\r\n",
    "Documentary\r\n",
    "Drama\r\n",
    "Fantasy\r\n",
    "Film-Noir\r\n",
    "Horror\r\n",
    "Musical\r\n",
    "Mystery\r\n",
    "Romance\r\n",
    "Sci-Fi\r\n",
    "Thriller\r\n",
    "War\r\n",
    "Western\r\n",
    "(no genres listed)\r\n",
    "Links Data File Structure (links.csv)\r\n",
    "Identifiers that can be used to link to other sources of movie data are contained in the file links.csv. Each line of this file after the header row represents one movie, and has the following format:\r\n",
    "\r\n",
    "* movieId is an identifier for movies used by https://movielens.org. E.g., the movie Toy Story has the link https://movielens.org/movies/1.\r\n",
    "\r\n",
    "* imdbId is an identifier for movies used by http://www.imdb.com. E.g., the movie Toy Story has the link http://www.imdb.com/title/tt0114709/.\r\n",
    "\r\n",
    "* tmdbId is an identifier for movies used by https://www.themoviedb.org. E.g., the movie Toy Story has the link https://www.themoviedb.org/movie/862.\r\n",
    "\r\n",
    "* As described in this article, the tag genome encodes how strongly movies exhibit particular properties represented by tags (atmospheric, thought-provoking, realistic, etc.). The tag genome was computed using a machine learning algorithm on user-contributed content including tags, ratings, and textual reviews.\r\n",
    "\r\n",
    "* The genome is split into two files. The file genome-scores.csv contains movie-tag relevance data in the following format:\r\n",
    "\r\n",
    "* The second file, genome-tags.csv, provides the tag descriptions for the tag IDs in the genome file, in the following format:\r\n",
    "tagId,tag"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import dataset\r\n",
    "train_df = pd.read_csv('train.csv')\r\n",
    "test_df = pd.read_csv('test.csv')\r\n",
    "tags_df = pd.read_csv('tags.csv')\r\n",
    "movies_df = pd.read_csv('movies.csv')\r\n",
    "links_df = pd.read_csv('links.csv')\r\n",
    "imdb_df = pd.read_csv('imdb_data.csv')\r\n",
    "genome_tags = pd.read_csv('genome_tags.csv')\r\n",
    "genome_score = pd.read_csv('genome_scores.csv')\r\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tags_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movies_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "links_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imdb_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "genome_tags.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "genome_score.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample_submission.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EDA\n",
    "\n",
    "Exploratory Data Analysis (EDA) is a fundamental part of the Machine Learning process. The data is analysed in order to extract information that a model may overlook. In this section, we will summarise the main characteritics of the data and also look into the sentiment classes provided in our training datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find the number of times a user has rated, create a data frame with the count by userId\r\n",
    "train_user = pd.DataFrame(\r\n",
    "    train_df['userId'].value_counts()).reset_index()\r\n",
    "train_user.rename(columns={'index':'userId','userId':'count'},\r\n",
    "                  inplace=True)\r\n",
    "train_user.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Grouping the users within a certain range aides in determining the common userId's and the new ones.\r\n",
    "group_one = train_user.loc[(train_user['count'] > 0) & \r\n",
    "            (train_user['count'] < 50),\r\n",
    "            'userId'].value_counts().sum()\r\n",
    "group_two = train_user.loc[(train_user['count'] >= 50) & \r\n",
    "            (train_user['count'] < 500),\r\n",
    "            'userId'].value_counts().sum()\r\n",
    "group_three = train_user.loc[(train_user['count'] >= 500) & \r\n",
    "            (train_user['count'] < 1000),\r\n",
    "            'userId'].value_counts().sum()\r\n",
    "group_four = train_user.loc[(train_user['count'] >= 1000) & \r\n",
    "            (train_user['count'] < 1500),\r\n",
    "            'userId'].value_counts().sum()\r\n",
    "group_five = train_user.loc[(train_user['count'] >= 1500),\r\n",
    "            'userId'].value_counts().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# To give us insight in the spread, we used figures to determine the spread.\r\n",
    "trial_error = np.array([['group_one', group_one,\r\n",
    "                         'ratings_count between 1 and 50'],\r\n",
    "                        ['group_two', group_two,\r\n",
    "                         'ratings_count between 50 and 500'],\r\n",
    "                        ['group_three', group_three,\r\n",
    "                         'ratings_count between 500 and 1000'],\r\n",
    "                        ['group_four', group_four,\r\n",
    "                         'ratings_count between 1000 and 1500'],\r\n",
    "                        ['group_five', group_five,\r\n",
    "                         'ratings_count greater than 1500']])\r\n",
    "trial_error_df = pd.DataFrame({'group': trial_error[:, 0],\r\n",
    "                               'userId_grouping': trial_error[:, 1],\r\n",
    "                               'explanation': trial_error[:, 2]})\r\n",
    "fig = px.bar(trial_error_df,\r\n",
    "             x=trial_error_df[\"group\"],\r\n",
    "             y=trial_error_df[\"userId_grouping\"],\r\n",
    "             color=trial_error_df[\"group\"],\r\n",
    "             title='Grouped Rating Distribustion')\r\n",
    "fig.show()\r\n",
    "trial_error_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As seen above majority of the ratings have been done by relatively new users or users who have inconsistent rating mannerisms. Based on this information we had to look for alternative ways of obtaining similarities between users by looking into the ratings per movie"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find the number of times a specific rating has been assigned, created a data frame with the count by rating.\r\n",
    "train_rating = pd.DataFrame(\r\n",
    "    train_df['rating'].value_counts()).reset_index()\r\n",
    "train_rating.rename(\r\n",
    "    columns={'index': 'rating', 'rating': 'count'}, inplace=True)\r\n",
    "train_rating.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Understanding the distribution of ratings is key to finding common traits between users.\r\n",
    "fig = px.bar(train_rating, x=train_rating['rating'],\r\n",
    "             y=train_rating['count'],\r\n",
    "             color=train_rating['rating'],\r\n",
    "             title='Distribustion by Rating')\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As seen from the above distribution by rating figure, rating 4 has a count of 2.652977M. Which clearly indicates to us that the users in the dataset will opt for giving movies a rating of 4."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Data Frame outlining the size of our data\r\n",
    "dataframes = ['train_df', 'test_df', 'tags_df', 'imdb_df',\r\n",
    "              'links_df', 'movies_df', 'genome_tags', 'genome_score']\r\n",
    "sizes = [len(train_df), len(test_df), len(tags_df),\r\n",
    "         len(imdb_df), len(links_df), len(movies_df),\r\n",
    "         len(genome_tags), len(genome_score)]\r\n",
    "total_size_df = pd.DataFrame(list(zip(dataframes, sizes)),\r\n",
    "                             columns=['dataframe', 'sizes'])\r\n",
    "total_size_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(total_size_df[total_size_df['sizes'] < 70000].sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_row = {'dataframe': 'other', 'sizes': 180530}\r\n",
    "total_size_df = total_size_df.append(new_row,\r\n",
    "                                     ignore_index=True)\r\n",
    "total_size_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# By refining the data frame we were able to see the distribution of the overall data.\r\n",
    "total_size_df = total_size_df[total_size_df['sizes'] > 100000]\r\n",
    "total_size_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "explodeTuple = (0.0, 0.0, 0.0, 0.0, 0.4)\r\n",
    "fig1, ax1 = plt.subplots()\r\n",
    "ax1.pie(total_size_df['sizes'].values,\r\n",
    "        labels=total_size_df['dataframe'].values,\r\n",
    "        explode=explodeTuple,\r\n",
    "        startangle=90, autopct='%1.1f%%')\r\n",
    "ax1.axis('equal')\r\n",
    "plt.title('Distribution of overall Data Frames')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len_list = [['train_df', len(train_df)], ['tags_df', len(tags_df)],\r\n",
    "            ['imdb_df', len(imdb_df)], ['links_df', len(links_df)],\r\n",
    "            ['movies_df', len(movies_df)],\r\n",
    "            ['genome_tags', len(genome_tags)],\r\n",
    "            ['genome_score', len(genome_score)]]\r\n",
    "len_df = pd.DataFrame(len_list,\r\n",
    "                      columns=['Dataset', 'Size'])\r\n",
    "fig = px.bar(len_df, x=len_df['Dataset'],\r\n",
    "             y=len_df['Size'],\r\n",
    "             color=len_df['Dataset'],\r\n",
    "             title='Distribution of overall Data Frames')\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Missing values, mainly known as null values, occur due to multiple reasons including errors whilst collecting data. These values are either removed because they add no value to the output of the models or ignored depending on the amount of null values contained within a data frame; all data has to be valid and valued. Duplicates are also removed as they do not provide any new information. The reduced number of values also result in less model run time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Obtaining total null values in each Data Frames columns\r\n",
    "train_count = pd.DataFrame(train_df.isnull().sum())\r\n",
    "test_count = pd.DataFrame(test_df.isnull().sum())\r\n",
    "tags_count = pd.DataFrame(tags_df.isnull().sum())\r\n",
    "movies_count = pd.DataFrame(movies_df.isnull().sum())\r\n",
    "links_count = pd.DataFrame(links_df.isnull().sum())\r\n",
    "imdb_count = pd.DataFrame(imdb_df.isnull().sum())\r\n",
    "genomet_count = pd.DataFrame(genome_tags.isnull().sum())\r\n",
    "genomes_count = pd.DataFrame(genome_score.isnull().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tags_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.bar(tags_count.index,\r\n",
    "        tags_count.values.reshape(len(tags_count), ),\r\n",
    "        color='purple')\r\n",
    "plt.xlabel('column_name')\r\n",
    "plt.ylabel('count')\r\n",
    "plt.title('Null value count in tags_df')\r\n",
    "plt.show()\r\n",
    "tags_df[tags_df.isnull().any(axis=1)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movies_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "links_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.bar(links_count.index,\r\n",
    "        links_count.values.reshape(len(links_count), ),\r\n",
    "        color='orange')\r\n",
    "plt.xlabel('column_name')\r\n",
    "plt.ylabel('count')\r\n",
    "plt.title('Null value count in links_df')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imdb_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.bar(imdb_count.index,\r\n",
    "        imdb_count.values.reshape(len(imdb_count), ),\r\n",
    "        color='red')\r\n",
    "plt.xlabel('column_name')\r\n",
    "plt.ylabel('count')\r\n",
    "plt.title('Null value count in imdb_df')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "genomet_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "genomes_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the above resluts, majority of the data frames had no null values present. Removing the null values could grant a more refined data depending on the amount of null values present. The imdb_df had a large amount of null values and dropping these rows would have resulted in a smaller data set which inturn could play a role in the long run."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualising Common Attributes/Correlation For Each Dataframe\n",
    "\n",
    "In statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data. In the broadest sense correlation is any statistical association, though it commonly refers to the degree to which a pair of variables are linearly related. The correlation coefficient is measured on a scale that varies from + 1 through 0 to - 1. Complete correlation between two variables is expressed by either + 1 or -1. When one variable increases as the other increases the correlation is positive; when one decreases as the other increases it is negative. Complete absence of correlation is represented by 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Correlation between the train_df and tags_df\r\n",
    "corr1 = pd.concat([train_df, tags_df], axis=1).corr()\r\n",
    "corr1.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = sns.heatmap(corr1, vmin=0,vmax=5,center=1,cmap=\"RdBu_r\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finding values in the UserID columns of the tags and train data frame.\r\n",
    "common_at = pd.DataFrame(train_df['userId'].isin(tags_df['userId']).\r\n",
    "                         value_counts())\r\n",
    "plt.bar(['Not Present', 'Present'],\r\n",
    "        common_at.values.reshape(len(common_at), ),\r\n",
    "        color='green')\r\n",
    "plt.xlabel('Values present/absent in both Data Frames')\r\n",
    "plt.ylabel('count_in_millions')\r\n",
    "plt.title('common_attributes between the train and tags data frames')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not many rows have common attributes we can use to link the train_df dataframe with the tags_df dataframe. Knowing the user and the type of genre they prefer to view, we can make a calculated estimate based on their watch history. Finding a link between the tables can increase the amount of variables used to predict the rating based on the user preferences."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finding values in the MovieID columns of the tags and train data frame.\r\n",
    "common_at2 = pd.DataFrame(train_df['movieId'].isin(tags_df['movieId']).\r\n",
    "                          value_counts())\r\n",
    "plt.bar(['Not Present', 'Present'],\r\n",
    "        common_at2.values.reshape(len(common_at2), ),\r\n",
    "        color='green')\r\n",
    "plt.xlabel('Values present/absent in both Data Frames ')\r\n",
    "plt.ylabel('count_in_millions')\r\n",
    "plt.title('common_attributes between the train and tags data frames')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finding values in the Timestamp columns of the tags and train data frame.\r\n",
    "common_at = pd.DataFrame(train_df['timestamp'].isin(tags_df['timestamp']).\r\n",
    "                         value_counts())\r\n",
    "plt.bar(['Not Present', 'Present'],\r\n",
    "        common_at.values.reshape(len(common_at), ),\r\n",
    "        color='orange')\r\n",
    "plt.xlabel('Values present/absent in both Data Frames')\r\n",
    "plt.ylabel('count_in_millions')\r\n",
    "plt.title('common_attributes between the train and tags data frames')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finding values in the MovieID columns of the links and movies data frame.\r\n",
    "common_at1 = pd.DataFrame(movies_df['movieId'].isin(links_df['movieId']).\r\n",
    "                          value_counts())\r\n",
    "plt.bar(['Present'],\r\n",
    "        common_at1.values.reshape(len(common_at1), ),\r\n",
    "        color='red')\r\n",
    "plt.xlabel('Values present/absent in both Data Frames')\r\n",
    "plt.ylabel('count')\r\n",
    "plt.title('common_attributes between the movies and links data frame')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checked for common attributes between different data frames. These attributes assist us in extending our understanding of the similarities between ratings based on: Movie Genres, Directors, Movie Budgets, Movie Titles, etc.\n",
    "\n",
    "Based on the information provided, we able to deduce the following: \n",
    "\n",
    "1. Although the train_df and the tags_df have similiar users ID's, majority of the users are new or inconsistent raters.\n",
    "2. The common attributes are minimal between the train_df and tags_df.\n",
    "3. Although there are a few users with similiar ID's, these users have no common attributes interms of the movies watched or the length of the movies.\n",
    "4. The table with the most common links are the movie_df and the links_df which have common attributes in the movie ID's column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Merged the train and movies data frame to increase the data utilized.\r\n",
    "movie_data = pd.merge(train_df, movies_df, on='movieId')\r\n",
    "movie_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The average rating per title.\r\n",
    "movie_data.groupby('title')['rating'].mean().head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movie_data.groupby('title')['rating'].mean().sort_values(ascending=False).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The average number of times a movie has been rated.\r\n",
    "movie_data.groupby('title')['rating'].count().sort_values(ascending=False).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ratings_mean_count = pd.DataFrame(movie_data.groupby('movieId')['rating'].\r\n",
    "                                  mean())\r\n",
    "ratings_mean_count['rating_counts'] = pd.DataFrame(movie_data.\r\n",
    "                                                   groupby('movieId')\r\n",
    "                                                   ['rating'].count())\r\n",
    "ratings_mean_count.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8, 6))\r\n",
    "plt.rcParams['patch.force_edgecolor'] = True\r\n",
    "sns.jointplot(x='rating', y='rating_counts',\r\n",
    "              data=ratings_mean_count,\r\n",
    "              alpha=0.4)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The average rating is based on the titles of the movies. For instance, Selling Isobel (2018) received an averaging of 5 stars, these averages could be misleading. Users could have rated the movies once and this could have increased the average rating. Shawshank Redemption, The (1994) had a total of 32831 ratings but due to the imabalance between user and ratings, the average ratings dropped. The inconsistency in the data could essentially lead to a biased model due to these observations. Grouping the ratings by the genre and finding the links between title of the movie and the average rating aided us in determining the variables which play a role in predicting the rating."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Cloud\n",
    "\n",
    "Word Cloud is a data visualization technique used for representing text data in which the size of each word indicates its frequency or importance. Significant textual data points can be highlighted using a word cloud. Word clouds are widely used for analyzing data from social network websites."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "comment_words = ''\r\n",
    "stopwords = set(STOPWORDS)\r\n",
    "\r\n",
    "# iterate through the csv file\r\n",
    "for val in tags_df['tag']:\r\n",
    "\r\n",
    "    # typecaste each val to string\r\n",
    "    val = str(val)\r\n",
    "\r\n",
    "    # split the value\r\n",
    "    tokens = val.split()\r\n",
    "\r\n",
    "    # Converts each token into lowercase\r\n",
    "    for i in range(len(tokens)):\r\n",
    "        tokens[i] = tokens[i].lower()\r\n",
    "\r\n",
    "    comment_words += \" \".join(tokens)+\" \"\r\n",
    "  \r\n",
    "wordcloud = WordCloud(width=800, height=800,\r\n",
    "                      background_color='black',\r\n",
    "                      stopwords=stopwords,\r\n",
    "                      min_font_size=10).generate(comment_words)\r\n",
    "\r\n",
    "# plot the WordCloud image\r\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\r\n",
    "plt.imshow(wordcloud)\r\n",
    "plt.axis(\"off\")\r\n",
    "plt.title('Distribution of words in the tags data frame by Tags')\r\n",
    "plt.tight_layout(pad=0)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "value_count = pd.DataFrame(tags_df['tag'].\r\n",
    "                           value_counts()).reset_index()\r\n",
    "value_count.rename(columns = {'index': 'genre', 'tag': 'count'},\r\n",
    "                   inplace = True)\r\n",
    "value_count.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distribution of genres and the amount of ratings that a certain genre assisted in finding similarities between viewers and their ratings. With majority of the ratings revolving around 'sci-fi' movies and minority around 'voice overs'. Seeing the inconsistency incertain genre's we decided to obtain movie genres that have a total number of ratings count over 2500 to ensure we have consistency in our data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "comment_words = ''\r\n",
    "stopwords = set(STOPWORDS)\r\n",
    "\r\n",
    "# iterate through the csv file\r\n",
    "for val in genome_tags['tag']:\r\n",
    "\r\n",
    "    # typecaste each val to string\r\n",
    "    val = str(val)\r\n",
    "\r\n",
    "    # split the value\r\n",
    "    tokens = val.split()\r\n",
    "\r\n",
    "    # Converts each token into lowercase\r\n",
    "    for i in range(len(tokens)):\r\n",
    "        tokens[i] = tokens[i].lower()\r\n",
    "\r\n",
    "    comment_words += \" \".join(tokens)+\" \"\r\n",
    "\r\n",
    "wordcloud = WordCloud(width=800, height=800,\r\n",
    "                      background_color='black',\r\n",
    "                      stopwords=stopwords,\r\n",
    "                      min_font_size=10).generate(comment_words)\r\n",
    "\r\n",
    "# plot the WordCloud image\r\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\r\n",
    "plt.imshow(wordcloud)\r\n",
    "plt.axis(\"off\")\r\n",
    "plt.title('Common words within the genome_tags, tags column')\r\n",
    "plt.tight_layout(pad=0)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are able to deduce the importance of certain words that could play a role in the functionality of our algorithem. The most used words in the genome_tags were:\n",
    "1. good\n",
    "2. war\n",
    "3. oscar best\n",
    "4. based on a true story\n",
    "5. comedy\n",
    "\n",
    "Viewers base their choices on a plethora of information ranginng from movie title, length, budget, actors present etc. Using this information, obtaining predictions that have a low RMSE score would be easier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_com_user = train_df.groupby('userId')\r\n",
    "train_com_user.get_group(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_com_user.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Release Year\n",
    "\n",
    "We will explore the release year of the movies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dates = []\r\n",
    "for title in movies_df['title']:\r\n",
    "    if title[-1] == \" \":\r\n",
    "        year = title[-6: -2]\r\n",
    "        try:\r\n",
    "            dates.append(int(year))\r\n",
    "        except:\r\n",
    "            dates.append(9999)\r\n",
    "    else:\r\n",
    "        year = title[-5: -1]\r\n",
    "        try:\r\n",
    "            dates.append(int(year))\r\n",
    "        except:\r\n",
    "            dates.append(9999)\r\n",
    "\r\n",
    "movies_df['release year'] = dates\r\n",
    "movies_df['release year'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(movies_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movies_df[movies_df['release year'] == 9999].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movies_df[(movies_df['release year'] > 1888) &\r\n",
    "          (movies_df['release year'] < 2021)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = pd.DataFrame(movies_df['release year'].\r\n",
    "                       value_counts()).reset_index()\r\n",
    "dataset.rename(columns={'index': 'year', 'release year': 'count'},\r\n",
    "               inplace=True)\r\n",
    "dataset.head(50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting the release years\r\n",
    "fig = px.bar(dataset, x=dataset['year'],\r\n",
    "             y=dataset['count'],\r\n",
    "             color=dataset['year'],\r\n",
    "             title='Movies released per release year')\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The earliest release year of a movie in our dataset goes as far back to 1874."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploring Movie Genre"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "genres = pd.DataFrame(movies_df['genres'].\r\n",
    "                      str.split(\"|\").\r\n",
    "                      tolist(),\r\n",
    "                      index=movies_df['movieId']).stack()\r\n",
    "genres = genres.reset_index([0, 'movieId'])\r\n",
    "genres.columns = ['movieId', 'Genre']\r\n",
    "genres.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\r\n",
    "sns.countplot(x='Genre',\r\n",
    "              data=genres,\r\n",
    "              palette='CMRmap',\r\n",
    "              order=genres['Genre'].\r\n",
    "              value_counts().index)\r\n",
    "plt.xticks(rotation=90)\r\n",
    "plt.xlabel('Genre', size=20)\r\n",
    "plt.ylabel('Count', size=20)\r\n",
    "plt.title('Distribution of Movie Genres', size=25)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to a study published by Amy Waston (Favorite film genres in the U.S. 2018, by gender) that can be found on https://www.statista.com/statistics/254115/favorite-movie-genres-in-the-us/ suggests that the top two genres liked by both men and women are Comedys and Dramas. From above results we can see that Drama and Comedy are the movie genre that the viewers would most likely would watch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploring Movie Budget"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_l = list(imdb_df['budget'])\r\n",
    "print(type(new_l[9]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imdb_df['runtime'] = imdb_df['runtime'].fillna(imdb_df['runtime'].mean())\r\n",
    "imdb_df.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imdb_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imdb_df['budget'] = imdb_df['budget'].str.replace('[\\,]', '', regex=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clean_txt(text):\r\n",
    "    text = re.sub(r'[0-9]+', \"\", str(text))\r\n",
    "    return text\r\n",
    "\r\n",
    "imdb_df['currency'] = imdb_df['budget'].apply(clean_txt)\r\n",
    "imdb_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "currencies = list(imdb_df['currency'])\r\n",
    "# Number of currencies\r\n",
    "len(set(currencies))-1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "currencies_count_df = pd.DataFrame(imdb_df['currency'].\r\n",
    "                                   value_counts()).reset_index()\r\n",
    "currencies_count_df.rename(columns={'index': 'currency', 'currency': 'count'},\r\n",
    "                           inplace=True)\r\n",
    "currencies_count_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = px.bar(currencies_count_df, x=currencies_count_df['currency'],\r\n",
    "             y=currencies_count_df['count'],\r\n",
    "             color=currencies_count_df['currency'],\r\n",
    "             title='Currency Type Distribution')\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "More than 71% of the data in the budget column are null values. The budget column contains different currencies with the US Dollar holding the majority. The exchange rates change gradually over time, with time value of money, money loses value over time so comparing or changing to one currency will not be ideal."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Models\n",
    "\n",
    "For each model in this section, we will prepare the data and train the model. The reason for this is that each model requires different type of preprocessing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collaborative Filtering (Singular Value Decomposition)\r\n",
    "\r\n",
    "The collaborative filtering approach builds models based on userâ€™s past behaviors as well as similar decisions made by other users. This model is used to predict items (or ratings for items) that the user may have an interest in. \r\n",
    "Within collaborative filtering, there are two well-known distinct approaches:\r\n",
    "\r\n",
    "1. Memory-Based: models calculate the similarities between users / items based on user-item rating pairs.\r\n",
    "2. Model-Based: models use some sort of machine learning algorithm to estimate the ratings.\r\n",
    "\r\n",
    "For this model, we will be using the model-based approach, in particular, the singular value decomposition (SVD).\r\n",
    "\r\n",
    "In the SVD model, an estimated rating of user u on item i is calculated as:\r\n",
    "![image.png](data:image/png;base64,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)\r\n",
    "* where Î¼ is the overall average rating, and every other parameter is calculated from the model with a gradient descent method. \r\n",
    "* The model will then try to fit this estimated rating on all the known ratings, minimise the MSE (mean squared error), and return the closest fit. \r\n",
    "* báµ¤ and báµ¢ are scalars, they represent the biases of the user u or item i. \r\n",
    "* páµ¤ and qáµ¢ are vectors,.they are the actual matrix-factorisation part of the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = train_df.drop(['timestamp'], axis=1)\r\n",
    "data = data.reset_index(drop=True)\r\n",
    "\r\n",
    "print(data.shape)\r\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reader = Reader(rating_scale=(0.0, 5.0))\r\n",
    "df = Dataset.load_from_df(data[['userId', 'movieId', 'rating']], reader)\r\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainset, testset = train_test_split(df, test_size=0.10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# modelstart = time.time()\r\n",
    "\r\n",
    "# Contains default parameters\r\n",
    "algo = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\r\n",
    "algo.fit(trainset)\r\n",
    "\r\n",
    "predictions = algo.test(testset)\r\n",
    "rmse_svd = accuracy.rmse(predictions)\r\n",
    "print('RMSE: ', rmse_svd)\r\n",
    "# print(\"Model Runtime: %0.2f seconds\" % ((time.time() - modelstart)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collaborative Filtering Using Cosine Similarity\r\n",
    "\r\n",
    "Cosine similarity is a metric used to measure how similar the documents are irrespective of their size. Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create Data Frame based on the grouping of elements by userID\r\n",
    "user_id_avg = train_df.groupby(by=\"userId\", as_index=False)['rating'].mean()\r\n",
    "rating_avg = pd.merge(train_df, user_id_avg, on='userId')\r\n",
    "# Obtain the average rating difference by ubtracting rating minus mean rating\r\n",
    "rating_avg['adg_rating'] = rating_avg['rating_x'] - rating_avg['rating_y']\r\n",
    "rating_avg.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movieID_value = pd.DataFrame(rating_avg['movieId'].\r\n",
    "                             value_counts()).reset_index()\r\n",
    "movieID_value.rename(columns={'index': 'movieId', 'movieId': 'count'},\r\n",
    "                     inplace=True)\r\n",
    "movieID_value"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Merge Data frames to increase information\r\n",
    "rating_avg = pd.merge(movieID_value, rating_avg, on='movieId')\r\n",
    "rating_avg.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# To preserve disk memory, only include ratings above 1000 per user.\r\n",
    "rating_avg = rating_avg[rating_avg['count'] > 1000]\r\n",
    "rating_avg.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rating_avg.groupby('movieId')['adg_rating'].count().sort_values(ascending=False).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The distributrion of movie ID's by rating also contained movies with single ratings or ratings that could be seen as negligable. We decided to obtain the top 20 movie ID's and see how they are distributed. Based on the graphs, we noticed movie ID 318 had the most ratings and this aided in using a base movie to obtain similarities amoung users when using the cosine similarity method."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Modelling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final = pd.pivot_table(rating_avg,\r\n",
    "                       values='rating_x',\r\n",
    "                       index='userId',\r\n",
    "                       columns='movieId')\r\n",
    "\r\n",
    "final.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Obtain the best rated movie.\r\n",
    "best_ratings = final.iloc[317]\r\n",
    "best_ratings.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find the correlation of movie ratings based on the best rated movie.\r\n",
    "movies_like_318 = final.corrwith(best_ratings)\r\n",
    "corr_shawshank = pd.DataFrame(movies_like_318,\r\n",
    "                              columns=['correlation'])\r\n",
    "corr_shawshank.dropna(inplace=True)\r\n",
    "corr_shawshank.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_shawshank.sort_values('correlation', ascending=False).head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_shawshank = corr_shawshank.join(ratings_mean_count['rating_counts'])\r\n",
    "corr_shawshank.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_shawshank.reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trial = pd.merge(corr_shawshank, rating_avg, on='movieId')\r\n",
    "trial.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "attempt = pd.pivot_table(trial,\r\n",
    "                         values='correlation',\r\n",
    "                         index='userId',\r\n",
    "                         columns='movieId')\r\n",
    "attempt.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_user = attempt.apply(lambda row: row.fillna(row.mean()),\r\n",
    "                           axis=1)\r\n",
    "final_user.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fill the diagonal of the new table with Zeroes.\r\n",
    "np.fill_diagonal(final_user.values, 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find a predefined number of training samples closest in\r\n",
    "# distance to the new point.\r\n",
    "\r\n",
    "def find_n_neighbours(df, n):\r\n",
    "\r\n",
    "    order = np.argsort(df.values, axis=1)[:, : n]\r\n",
    "    df = df.apply(lambda x: pd.Series(x.sort_values(ascending=False)\r\n",
    "                  .iloc[:n].index,\r\n",
    "                  index=['top{}'.format(i) for i in range(1, n+1)]), axis=1)\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find a users top 3 favorite movies.\r\n",
    "sim_user_30_u = find_n_neighbours(final_user, 3)\r\n",
    "sim_user_30_u.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get users with similiar rating styles.\r\n",
    "\r\n",
    "def get_user_similar_movies(user1, user2):\r\n",
    "    common_movies = rating_avg[rating_avg.userId == user1].merge(\r\n",
    "        rating_avg[rating_avg.userId == user2],\r\n",
    "        on=\"movieId\",\r\n",
    "        how=\"inner\")\r\n",
    "    return common_movies.merge(movies_df, on='movieId')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# See if our algorithm is able to find similiar movies between two users.\r\n",
    "\r\n",
    "a = get_user_similar_movies(370, 86309)\r\n",
    "a = a.loc[:, ['rating_x_x', 'rating_x_y', 'title']]\r\n",
    "a.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dictionary to round numbers to the nearest userID.\r\n",
    "\r\n",
    "def dictionary_trial(item):\r\n",
    "    my_list = [col for col in final_user.columns]\r\n",
    "    my_dict = {'values': my_list}\r\n",
    "    answer = []\r\n",
    "\r\n",
    "    for x in my_dict['values']:\r\n",
    "        if x < item:\r\n",
    "            answer.append(x)\r\n",
    "        if x == item:\r\n",
    "            answer.append(item)\r\n",
    "    return (max(answer))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check if we are able to round of to the nearest user.\r\n",
    "dictionary_trial(195160)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict the rating based on the user and the movie chosen.\r\n",
    "\r\n",
    "def User_item_score(user, item):\r\n",
    "    mean = train_df.groupby(by=\"userId\", as_index=False)['rating'].mean()\r\n",
    "    # print(1)\r\n",
    "    a = sim_user_30_u[sim_user_30_u.index == user].values\r\n",
    "    # print(2)\r\n",
    "    b = a.squeeze().tolist()\r\n",
    "    # print(3)\r\n",
    "    c = final_user.loc[:, dictionary_trial(item)]\r\n",
    "    # print(4)\r\n",
    "    # print(c)\r\n",
    "    d = c[c.index.isin(b)]\r\n",
    "    # print(5)\r\n",
    "    # print(d)\r\n",
    "    f = d[d.notnull()]\r\n",
    "    # print(6)\r\n",
    "    # print(f)\r\n",
    "    avg_user = mean.loc[mean['userId'] == user, 'rating'].values[0]\r\n",
    "    # print(7)\r\n",
    "    # print(avg_user)\r\n",
    "    index = f.index.values.squeeze().tolist()\r\n",
    "    # print(8)\r\n",
    "    # print(index)\r\n",
    "    corr = final_user.loc[user, index]\r\n",
    "    # print(9)\r\n",
    "    fin = pd.concat([f, corr], axis=1)\r\n",
    "    # print(10)\r\n",
    "    fin.columns = ['adg_score', 'correlation']\r\n",
    "    # print(11)\r\n",
    "    fin['score'] = fin.apply(lambda x: x['adg_score'] * x['correlation'], axis=1)\r\n",
    "    # print(12)\r\n",
    "    nume = fin['score'].sum()\r\n",
    "    # print(13)\r\n",
    "    deno = fin['correlation'].sum()\r\n",
    "    # print(14)\r\n",
    "    final_score = avg_user + (nume / deno)\r\n",
    "    # print(15)\r\n",
    "    return final_score\r\n",
    "\r\n",
    "# score = User_item_score(129299, 129299)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check if we are able to predict based on similiar user ratings.\r\n",
    "score = User_item_score(129298, 129298)\r\n",
    "print(\"score (u,i) is\", score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sliced_df = train_df.iloc[0: 100, :]\r\n",
    "tester_df = sliced_df[['userId', 'movieId', 'rating']]\r\n",
    "tester_df['pred_rating'] = [User_item_score(tester_df['userId'][i],\r\n",
    "                                            tester_df['movieId'][i]) for i in list(tester_df.index)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tester_df['movieId'][129299]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Obtain the RMSE for the sample provided.\r\n",
    "rmse = mean_squared_error(tester_df['rating'].values,\r\n",
    "                          tester_df['pred_rating'].values,\r\n",
    "                          squared=False)\r\n",
    "print(\"RMSE: \", rmse)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Content-Based Filtering (Linear Regression)\n",
    "\n",
    "Content-Based recommenders treat recommendation as a user-specific classification problem and learn a classifier for the user's likes and dislikes based on an item's features. In this system, keywords are used to describe the items and a user profile is built to indicate the type of item this user likes.We Linear Regression for this model.\n",
    "\n",
    "Simple linear regression is a statistical method that shows the relationship between two continuous variables. This is represented by a straight line with the equation:\n",
    "$$ y = a + bx$$   \n",
    "where $a$ is the intercept of the line with the y-axis, and $b$ is the gradient.  \n",
    "The independent variable ($x$) is also known as the predictor and the dependent variable ($y$) is known as the target.\n",
    "\n",
    "We will merge each movie with it's genre, casts, director and plot keywords as way to find out how similar is the test movie to any movie the user has rated before, then rate the 'test movie' by the highest similarity in any rating category. This will assist us to categorise the movies each user has watched by rating."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dataframe we are working with.\r\n",
    "working_train = tester_df #.drop(columns='timestamp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Merge\r\n",
    "df_work = working_train.set_index('movieId').join([movies_df\r\n",
    "                                                [['movieId', 'genres']].\r\n",
    "                                                set_index('movieId'),\r\n",
    "                                                imdb_df[['movieId',\r\n",
    "                                                'title_cast',\r\n",
    "                                                'director',\r\n",
    "                                                'plot_keywords']].\r\n",
    "                                                set_index('movieId')],\r\n",
    "                                                how='left').reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def preprocessor(df):\r\n",
    "    \r\n",
    "    df_work['genres'] = ['' if x == '(no genres listed)' else x for x in df_work['genres']]\r\n",
    "\r\n",
    "    # filling missing values with 'nothing'... (emptying...?)\r\n",
    "    df_work.fillna('', inplace=True)\r\n",
    "\r\n",
    "    for col in df_work.select_dtypes('object').columns: # selecting 'object' columns\r\n",
    "\r\n",
    "        # removing white space\r\n",
    "        df_work[col] = [''.join(x.split()) for x in df_work[col]]\r\n",
    "\r\n",
    "        # substituting '|' with a white space\r\n",
    "        df_work[col] = [' '.join(x.split('|')) for x in df_work[col]]\r\n",
    "\r\n",
    "    # joining the features of interest\r\n",
    "    df_work['corpus'] =  df_work[df_work.select_dtypes('object').columns].apply(lambda x: ' '.join(x), axis=1)\r\n",
    "    return df_work[['movieId', 'userId', 'corpus']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Test = preprocessor(test_df)\r\n",
    "Test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = preprocessor(train_df.drop(columns=['timestamp'])) # DO NOT RUN THIS ON LOCAL COMPUTER"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = train_df['rating']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X['rating'] = y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X1 = X.drop(columns=['rating', 'userId', 'movieId'])\r\n",
    "T1 = Test.drop(columns=['userId', 'movieId'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv = CountVectorizer()\r\n",
    "X_mat =cv.fit_transform(X1['corpus'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Test_mat = cv.transform(T1['corpus'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_mat.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sample.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Modelling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "estimators2 = []\r\n",
    "estimators2.append(('standardize',\r\n",
    "                    StandardScaler(with_mean=False)))\r\n",
    "estimators2.append(('mod',\r\n",
    "                    LinearRegression()))\r\n",
    "model = Pipeline(estimators2)\r\n",
    "model.fit(X_mat, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Collaborative Filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_df = pd.DataFrame(train_df['movieId'].value_counts()).reset_index()\r\n",
    "count_df.rename(columns = {'index':'movieId','movieId' : 'count'}, inplace = True)\r\n",
    "count_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_count =pd.merge(count_df, train_df ,on='movieId')\r\n",
    "train_count.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filter_user = train_count[train_count['count']>10000]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filter_user.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reader = Reader(rating_scale=(0, 5))\r\n",
    "data = Dataset.load_from_df(filter_user[['movieId',\r\n",
    "                                         'userId',\r\n",
    "                                         'rating']],\r\n",
    "                            reader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "benchmark = []\r\n",
    "# Iterate over all algorithms\r\n",
    "for algorithm in [NormalPredictor(),\r\n",
    "                  KNNBaseline(),\r\n",
    "                  KNNBasic(),\r\n",
    "                  KNNWithMeans(),\r\n",
    "                  KNNWithZScore(),\r\n",
    "                  BaselineOnly(),\r\n",
    "                  CoClustering(),\r\n",
    "                  SVD()]:\r\n",
    "    # Perform cross validation\r\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'],\r\n",
    "                             cv=3, verbose=False)\r\n",
    "\r\n",
    "    # Get results & append algorithm name\r\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\r\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).\r\n",
    "                                split(' ')[0].\r\n",
    "                                split('.')[-1]],\r\n",
    "                               index=['Algorithm']))\r\n",
    "    benchmark.append(tmp)\r\n",
    "\r\n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Using ALS')\r\n",
    "bsl_options = {'method': 'als',\r\n",
    "               'n_factors' : 300, \r\n",
    "               'lr_all':0.0085,\r\n",
    "               'reg_all' : 0.02,\r\n",
    "               'n_epochs':40,\r\n",
    "               'init_std_dev':0.01\r\n",
    "               }\r\n",
    "algo = SVD(bsl_options=bsl_options)\r\n",
    "cross_validate(algo, data, measures=['RMSE'],\r\n",
    "               cv=3, verbose=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training and validation set split for hypertuning\r\n",
    "\r\n",
    "train_set = data.build_full_trainset()\r\n",
    "# train_set, val_set = train_test_split(data, test_size=0.008, random_state=42)\r\n",
    "\r\n",
    "# Modelling of the SVD hypertuning\r\n",
    "algo = SVD(n_factors=300, \r\n",
    "                     lr_all=0.0085,\r\n",
    "                     reg_all=0.02,\r\n",
    "                     n_epochs=40,\r\n",
    "                     init_std_dev=0.01)\r\n",
    "algo.fit(train_set)\r\n",
    "\r\n",
    "# Predicting on the validation set\r\n",
    "# svd_hyper_predictions = algo.test(val_set)\r\n",
    "\r\n",
    "# Dictionary for the data to log for the SVD tuned model\r\n",
    "params = {'model_name': 'SVD_Tuned'}\r\n",
    "# metrics = {'RMSE': accuracy.rmse(svd_hyper_predictions)}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "submission_df = [algo.predict(row.userId, row.movieId) for _,row in test_df.iterrows()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_pred = pd.DataFrame(submission_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_pred=df_pred.rename(columns={'uid':'userId', 'iid':'movieId','est':'rating'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_pred.drop(['r_ui','details'],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_pred['Id']=df_pred.apply(lambda x:'%s_%s' % (x['userId'],x['movieId']),axis=1)\r\n",
    "df_pred['Id']=df_pred.apply(lambda x:'%s_%s' % (x['userId'],x['movieId']),axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop the features that will not be required for the submission\r\n",
    "df_pred.drop(['userId', 'movieId'], inplace=True, axis= 1)\r\n",
    "#Change positioning of columns\r\n",
    "df_pred = df_pred[['Id', 'rating']]\r\n",
    "# Create Submission file\r\n",
    "df_pred.to_csv(\"JS6_submission_full_trainset.csv\", index=False)\r\n",
    "df_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_pred.to_csv(\"JS6_submission_full_trainset_new_params.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Compare RMSE squared values between models\r\n",
    "# fig, caxis = plt.subplots(figsize=(12, 6))\r\n",
    "# rmse_x = ['Linear Regression',\r\n",
    "#           'BaselineOnly', 'SVD',\r\n",
    "#           'Cosine Similarity',\r\n",
    "#           'Baseline Only',\r\n",
    "#           'KNN Baseline',\r\n",
    "#           'KNN With Means',\r\n",
    "#           'KNN WIth Z Score',\r\n",
    "#           'KNN Basic',\r\n",
    "#           'CoClustering',\r\n",
    "#           'Normal Predictor']\r\n",
    "# rmse_y = [lr_rmse, baseline_rmse, rmse_svd, CF_cosine, baselineOnly,\r\n",
    "#           kNNBaseline, kNNWithMeans, kNNWithZScore, kNNBasic,\r\n",
    "#           coClustering, normal]\r\n",
    "# ax = sns.barplot(x=rmse_x, y=rmse_y, palette='plasma_r')\r\n",
    "# plt.title('RMSE Values of Models', fontsize=14)\r\n",
    "# plt.ylabel('RMSE')\r\n",
    "# plt.xticks(rotation=90)\r\n",
    "# for p in ax.patches:\r\n",
    "#     ax.text(p.get_x() + p.get_width()/2, p.get_y() + p.get_height(),\r\n",
    "#             round(p.get_height(), 2),\r\n",
    "#             fontsize=12, ha=\"center\",\r\n",
    "#             va='bottom')\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svd_params = dict(n_factors=100, n_epochs=20,\r\n",
    "                  lr_all=0.005, reg_all=0.02)\r\n",
    "\r\n",
    "lr_params = dict(fit_intercept=True, normalize=False,\r\n",
    "                 copy_X=True, n_jobs=None)\r\n",
    "\r\n",
    "baselineOnly_params = dict(verbose =True)\r\n",
    "\r\n",
    "knnbaseline_params = dict(k=40, min_k=1, sim_options={},\r\n",
    "                          bsl_options={}, verbose=True) \r\n",
    "\r\n",
    "knnwithmeans_params = dict(k=40, min_k=1,\r\n",
    "                           sim_options={}, verbose=True)\r\n",
    "\r\n",
    "knnwithzscore_params = dict(k=40, min_k=1,\r\n",
    "                            sim_options={}, verbose=True)\r\n",
    "                            \r\n",
    "knnbasic_params = dict(k=40, min_k=1,\r\n",
    "                       sim_options={}, verbose=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {'model type': 'SVD',\r\n",
    "          'scaler': 'standard scaler',\r\n",
    "          'params': str(svd_params),\r\n",
    "          'model type': 'Linear Regression',\r\n",
    "          'params': str(lr_params),\r\n",
    "          'model type': 'Baseline Only',\r\n",
    "          'params': str(baselineOnly_params),\r\n",
    "          'model type': 'KNNBaseline',\r\n",
    "          'params': str(knnbaseline_params),\r\n",
    "          'model type': 'KNNWithMeans',\r\n",
    "          'params': str(knnwithmeans_params),\r\n",
    "          'model type': 'KNNWithZScore',\r\n",
    "          'params': str(knnwithzscore_params),\r\n",
    "          'model type': 'KNNBasic',\r\n",
    "          'params': str(knnbasic_params),\r\n",
    "          'stratify': True\r\n",
    "          }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# metrics = {'RMSE_SVD': rmse_svd,\r\n",
    "#            'RMSE_LR': lr_rmse,\r\n",
    "#            'RMSE_BaselineOnly': baseline_rmse,\r\n",
    "#            'RMSE_Cosine': CF_cosine,\r\n",
    "#            'KNNBaesline': kNNBaseline,\r\n",
    "#            'KNNWithMeans': kNNWithMeans,\r\n",
    "#            'KNNWithZScore': kNNWithZScore,\r\n",
    "#            'KNNBasic': kNNBasic,\r\n",
    "#            'CoClustering': coClustering,\r\n",
    "#            'Normal': normal\r\n",
    "#            }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "experiment.log_dataset_hash(data)\r\n",
    "experiment.log_parameters(params)\r\n",
    "# experiment.log_metrics(metrics)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "experiment.end()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### End Comet Experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}